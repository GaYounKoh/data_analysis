{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## 결과 확인 용이\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "## preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## RF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## scoring\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "## rf 의사결정 나무 그래프\n",
    "from sklearn.tree import export_graphviz\n",
    "from subprocess import call\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "## vis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "sns.set_theme(context='notebook',   # 매체: paper, talk, poster\n",
    "              style='darkgrid',     # 기본 내장 테마\n",
    "              palette='deep',       # 그래프 색\n",
    "              font='Malgun Gothic', # 글꼴 종류 \n",
    "              font_scale=1,         # 글꼴 크기\n",
    "              rc=custom_params)     # 그래프 세부 사항\n",
    "\n",
    "## seed 고정\n",
    "import random\n",
    "user_seed = 42\n",
    "random.seed(user_seed) # seed 고정"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('DATA.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 변수 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar1 = data.TARGET\n",
    "tar2 = data.TARGET2A\n",
    "tar4 = data.ATM\n",
    "\n",
    "features = data.iloc[:,1:-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tar1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train, test split\n",
    "train, test = train_test_split(data, test_size = 0.2, stratify = data['TARGET']) # stratify : 균등 분할\n",
    "                                                                                      # 이래버리면 data leakage이긴 함.\n",
    "## X, Y 분리\n",
    "X_train, Y_train = train.iloc[:, 1:-4], train['TARGET']\n",
    "X_test, Y_test = test.iloc[:, 1:-4], test['TARGET']\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=300, random_state = user_seed)\n",
    "\n",
    "## random_state 42로 고정 후, id 열 제거 후))\n",
    "# 300에 57.3%이 현재 최선\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "## 점수 함수\n",
    "def get_clf_eval(Y_test, pred=None, pred_proba=None):\n",
    "    print('오차행렬 \\n', confusion_matrix(Y_test, Y_pred))\n",
    "    print('정확도 :', accuracy_score(Y_test, Y_pred))\n",
    "#     print('정밀도 : ',precision_score(Y_test, Y_pred))    # class 비율 균일하게 분할 시 작동 안함.\n",
    "#     print('재현율 :', recall_score(Y_test, Y_pred))    # class 비율 균일하게 분할 시 작동 안함.\n",
    "#     print('f1 score :', f1_score(Y_test, Y_pred))    # class 비율 균일하게 분할 시 작동 안함.\n",
    "#     print('roc auc score :', roc_auc_score(Y_test, Y_pred))\n",
    "\n",
    "\n",
    "get_clf_eval(Y_test)\n",
    "\n",
    "# print(f'Y_train : {Y_train}')\n",
    "print(f'Y_test : {np.array(Y_test)}')\n",
    "print(f'Y_pred : {Y_pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FI scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## linear하게 정렬하기\n",
    "dic = {X_train.columns[i] : model.feature_importances_[i] for i in range(len(X_train.columns))}\n",
    "item_li = sorted(dic.items(), key=lambda x:x[1], reverse=True)\n",
    "#\n",
    "\n",
    "item_keys = [i[0] for i in item_li]\n",
    "item_values = [i[1] for i in item_li]\n",
    "#\n",
    "\n",
    "# sns.scatterplot(model.feature_importances_, X_train.columns)\n",
    "sns.scatterplot(item_values, item_keys)\n",
    "plt.savefig('tar1_FI')\n",
    "\n",
    "### tar1 all vis\n",
    "# Model (can also use single decision tree)\n",
    "model = RandomForestClassifier(n_estimators=450, random_state = user_seed)\n",
    "\n",
    "# Train\n",
    "model.fit(features, tar1)\n",
    "# Extract single tree\n",
    "estimator = model.estimators_[5]\n",
    "\n",
    "tar1_class = ['Unbanked','Under_Banked', 'Fully_Banked']\n",
    "\n",
    "# Export as dot file\n",
    "export_graphviz(estimator, out_file='tree.dot', \n",
    "                feature_names = list(features.columns),\n",
    "                class_names = tar1_class,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png using system command (requires Graphviz)\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'all_vis_tree_tar1.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "Image(filename = 'all_vis_tree_tar1.png', height=300, width= 450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tar3\n",
    "- missing data는 listwise하게 없애기 <br>\n",
    "(listwise란? 그 행의 데이터를 다 없애는 방식. `dropna`로 해결 됨.) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dropna = data.dropna(axis=0)\n",
    "tar3 = data_dropna.TARGET2B\n",
    "features_dropna = data_dropna.iloc[:,1:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test split\n",
    "train, test = train_test_split(data_dropna, test_size = 0.2, stratify = data_dropna['TARGET2B']) # stratify : 균등 분할\n",
    "                                                                                      # 이래버리면 data leakage이긴 함.\n",
    "# X, Y 분리\n",
    "X_train, Y_train = train.iloc[:, 1:-4], train['TARGET2B']\n",
    "X_test, Y_test = test.iloc[:, 1:-4], test['TARGET2B']\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=300, random_state = user_seed)\n",
    "\n",
    "## random_state 42로 고정 후, id 열 제거 후))\n",
    "# 300에 64%\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "## 점수 함수\n",
    "def get_clf_eval(Y_test, pred=None, pred_proba=None):\n",
    "    print('오차행렬 \\n', confusion_matrix(Y_test, Y_pred))\n",
    "    print('정확도 :', accuracy_score(Y_test, Y_pred))\n",
    "\n",
    "\n",
    "get_clf_eval(Y_test)\n",
    "\n",
    "# print(f'Y_train : {Y_train}')\n",
    "print(f'Y_test : {np.array(Y_test)}')\n",
    "print(f'Y_pred : {Y_pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FI scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## linear하게 정렬하기\n",
    "dic = {X_train.columns[i] : model.feature_importances_[i] for i in range(len(X_train.columns))}\n",
    "item_li = sorted(dic.items(), key=lambda x:x[1], reverse=True)\n",
    "#\n",
    "\n",
    "item_keys = [i[0] for i in item_li]\n",
    "item_values = [i[1] for i in item_li]\n",
    "#\n",
    "\n",
    "# sns.scatterplot(model.feature_importances_, X_train.columns)\n",
    "sns.scatterplot(item_values, item_keys)\n",
    "plt.savefig('tar3_FI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tar1 all vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (can also use single decision tree)\n",
    "model = RandomForestClassifier(n_estimators=450, random_state = user_seed)\n",
    "\n",
    "# Train\n",
    "model.fit(features_dropna, tar3)\n",
    "# Extract single tree\n",
    "estimator = model.estimators_[5]\n",
    "\n",
    "\n",
    "\n",
    "tar3_class = ['Under_Banked_No','Under_Banked_Yes']\n",
    "\n",
    "# Export as dot file\n",
    "export_graphviz(estimator, out_file='tree.dot', \n",
    "                feature_names = list(X_train.columns),\n",
    "                class_names = tar3_class,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png using system command (requires Graphviz)\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'all_vis_tree_tar3.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "Image(filename = 'all_vis_tree_tar3.png', height=300, width= 450)\n",
    "\n",
    "\n",
    "# Visualization\n",
    "## tar1\n",
    "# Model (can also use single decision tree)\n",
    "model = RandomForestClassifier(n_estimators=10, max_depth = 3, max_features = 4, random_state = user_seed)\n",
    "\n",
    "# Train\n",
    "model.fit(features, tar1)\n",
    "# Extract single tree\n",
    "estimator = model.estimators_[5]\n",
    "\n",
    "tar1_class = ['Unbanked','Under_Banked', 'Fully_Banked']\n",
    "\n",
    "# Export as dot file\n",
    "export_graphviz(estimator, out_file='tree.dot', \n",
    "                feature_names = list(features.columns),\n",
    "                class_names = tar1_class,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png using system command (requires Graphviz)\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree_tar1(3,4,seed42).png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "Image(filename = 'tree_tar1(3,4,seed42).png', height=300, width= 450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tar3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dropna = data.dropna(axis=0)\n",
    "tar3 = data_dropna.TARGET2B\n",
    "features_dropna = data_dropna.iloc[:,1:-4]\n",
    "\n",
    "\n",
    "# Model (can also use single decision tree)\n",
    "model = RandomForestClassifier(n_estimators=10, max_depth = 3, max_features = 4, random_state = user_seed)\n",
    "\n",
    "# Train\n",
    "model.fit(features_dropna, tar3)\n",
    "# Extract single tree\n",
    "estimator = model.estimators_[5]\n",
    "\n",
    "\n",
    "tar3_class = ['Under_Banked_No','Under_Banked_Yes']\n",
    "\n",
    "\n",
    "# Export as dot file\n",
    "export_graphviz(estimator, out_file='tree.dot', \n",
    "                feature_names = list(features_dropna.columns),\n",
    "                class_names = tar3_class,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png using system command (requires Graphviz)\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree_tar3(3,4,seed42).png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "Image(filename = 'tree_tar3(3,4,seed42).png', height=300, width= 450)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
